# Concurrent Web Scraper in Go ğŸ•¸ï¸âš™ï¸

This is a simple and efficient concurrent web scraping tool built using Go. It demonstrates how to use goroutines, channels, and worker pools to fetch and extract links (`<a href="">`) from multiple web pages in parallel.

## ğŸ”§ Features

- Fetches web pages concurrently using a worker pool
- Extracts and prints all links (`href`) from each page
- Uses `goquery` for HTML parsing (jQuery-like)
- Clean modular code with concurrency patterns

## ğŸ“ Project Structure

o-concurrent-scraper/
â”œâ”€â”€ main.go # Entry point, handles concurrency and workers
â”œâ”€â”€ scraper.go # Contains the HTML scraping logic
â”œâ”€â”€ go.mod # Go module file
â”œâ”€â”€ go.sum # Dependency verification file


## ğŸš€ How to Run

### 1. Clone the repo

```bash
git clone https://github.com/Destro3998/concurrent-web-scraper.git
cd concurrent-web-scraper

### 2. Make sure Go is Installed

go version

### 3. Run the scraper

go run main.go scraper.go

âœï¸ Sample Output

Links found on https://golang.org
 â†’ https://pkg.go.dev
 â†’ https://play.golang.org
 â†’ ...

Links found on https://github.com
 â†’ https://github.com/login
 â†’ https://github.com/signup
 â†’ ...


